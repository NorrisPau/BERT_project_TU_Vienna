{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predict sex with topic probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import matplotlib as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Load processed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "#1. Target vector Y (sex)\n",
    "df_topic_sex = pd.read_csv(\"C:/Users/norap/Documents/GitHub/Machine Learning NLP TU Wien/data/processed/df_topic_sex.csv\")\n",
    "\n",
    "#2. Feature Vector X (topic probabilities)\n",
    "probs_topic_df = pd.read_csv(\"C:/Users/norap/Documents/GitHub/Machine Learning NLP TU Wien/data/processed/probs_topic_df.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Profile_text  most_probable_topic  \\\n0      currently working international agent freight ...                   -1   \n1               dedicating everyday unbelievable badass.                   87   \n2      make nerdy software musicians, artists, experi...                   -1   \n3                 reading things written old dead people                    2   \n4                             work work work work + play                   77   \n...                                                  ...                  ...   \n52369  happiest times life came ran it-not ahead it. ...                   -1   \n52370  currently finishing school film production, em...                   20   \n52371  i'm civil engineer, enjoys helping citizens sa...                    0   \n52372  following dreams... \"you got dream... gotta pr...                  123   \n52373  work elderly people (psychotherapy case manage...                   -1   \n\n      Sex  GenderDummy_F  \n0       m              0  \n1       m              0  \n2       m              0  \n3       m              0  \n4       m              0  \n...    ..            ...  \n52369   f              1  \n52370   m              0  \n52371   m              0  \n52372   m              0  \n52373   m              0  \n\n[52374 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Profile_text</th>\n      <th>most_probable_topic</th>\n      <th>Sex</th>\n      <th>GenderDummy_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>currently working international agent freight ...</td>\n      <td>-1</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dedicating everyday unbelievable badass.</td>\n      <td>87</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>make nerdy software musicians, artists, experi...</td>\n      <td>-1</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>reading things written old dead people</td>\n      <td>2</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>work work work work + play</td>\n      <td>77</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>52369</th>\n      <td>happiest times life came ran it-not ahead it. ...</td>\n      <td>-1</td>\n      <td>f</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>52370</th>\n      <td>currently finishing school film production, em...</td>\n      <td>20</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52371</th>\n      <td>i'm civil engineer, enjoys helping citizens sa...</td>\n      <td>0</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52372</th>\n      <td>following dreams... \"you got dream... gotta pr...</td>\n      <td>123</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52373</th>\n      <td>work elderly people (psychotherapy case manage...</td>\n      <td>-1</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>52374 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_sex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Do a train/test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(probs_topic_df, df_topic_sex[\"GenderDummy_F\"], test_size=0.33, random_state=42) #random state to make it reproducible"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "2109     0\n13196    0\n44691    1\n27049    0\n2054     0\n        ..\n11284    1\n44732    1\n38158    0\n860      0\n15795    1\nName: GenderDummy_F, Length: 35090, dtype: int64"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "              0         1         2         3         4         5         6  \\\n2109   0.000685  0.000905  0.000974  0.001142  0.000485  0.000740  0.000590   \n13196  0.003366  0.050964  0.005073  0.002017  0.001711  0.002411  0.002597   \n44691  0.000008  0.000007  0.000009  0.000010  0.000006  0.000011  0.000008   \n27049  0.003204  0.002145  0.002397  0.001497  0.001864  0.001990  0.002514   \n2054   0.002126  0.002760  0.003468  0.001363  0.001216  0.001532  0.001914   \n...         ...       ...       ...       ...       ...       ...       ...   \n11284  0.000523  0.000643  0.000693  0.000893  0.000413  0.000555  0.000547   \n44732  0.002772  0.002114  0.001996  0.002052  0.001288  0.001730  0.002448   \n38158  0.001408  0.002021  0.002150  0.002780  0.000959  0.001524  0.001179   \n860    0.002694  0.021154  0.003418  0.001392  0.001302  0.001732  0.001978   \n15795  0.001341  0.001889  0.002124  0.001616  0.000764  0.001539  0.000964   \n\n              7         8         9  ...       360       361       362  \\\n2109   0.000813  0.000630  0.001158  ...  0.000796  0.001684  0.000710   \n13196  0.002938  0.001728  0.003586  ...  0.002848  0.001304  0.002608   \n44691  0.000014  0.000008  0.000010  ...  0.000013  0.000004  0.000009   \n27049  0.002048  0.001896  0.001914  ...  0.002614  0.001017  0.010982   \n2054   0.001806  0.001179  0.001723  ...  0.001903  0.000860  0.002932   \n...         ...       ...       ...  ...       ...       ...       ...   \n11284  0.000603  0.000507  0.000724  ...  0.000579  0.005467  0.000569   \n44732  0.001876  0.001525  0.002727  ...  0.002229  0.001095  0.002113   \n38158  0.001777  0.001255  0.002955  ...  0.001643  0.001993  0.001402   \n860    0.002040  0.001264  0.002375  ...  0.002091  0.000933  0.001997   \n15795  0.001665  0.001018  0.004638  ...  0.001959  0.000796  0.001161   \n\n            363       364       365       366       367       368       369  \n2109   0.001929  0.000775  0.001174  0.000757  0.004973  0.001106  0.001103  \n13196  0.001346  0.003839  0.003638  0.002926  0.002350  0.004168  0.005286  \n44691  0.000004  0.000007  0.000008  0.000013  0.000006  0.000013  0.000012  \n27049  0.001080  0.003761  0.002254  0.004858  0.001696  0.002612  0.003558  \n2054   0.000906  0.004433  0.003405  0.002967  0.001461  0.002277  0.004366  \n...         ...       ...       ...       ...       ...       ...       ...  \n11284  0.007300  0.000594  0.000900  0.000581  0.001389  0.000731  0.000729  \n44732  0.001209  0.001957  0.002387  0.002200  0.002319  0.005422  0.003803  \n38158  0.002226  0.001537  0.002533  0.001563  0.017039  0.002751  0.002489  \n860    0.000961  0.003120  0.002509  0.002187  0.001629  0.002810  0.003636  \n15795  0.000840  0.001407  0.001847  0.001452  0.001858  0.002538  0.003066  \n\n[35090 rows x 370 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>360</th>\n      <th>361</th>\n      <th>362</th>\n      <th>363</th>\n      <th>364</th>\n      <th>365</th>\n      <th>366</th>\n      <th>367</th>\n      <th>368</th>\n      <th>369</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2109</th>\n      <td>0.000685</td>\n      <td>0.000905</td>\n      <td>0.000974</td>\n      <td>0.001142</td>\n      <td>0.000485</td>\n      <td>0.000740</td>\n      <td>0.000590</td>\n      <td>0.000813</td>\n      <td>0.000630</td>\n      <td>0.001158</td>\n      <td>...</td>\n      <td>0.000796</td>\n      <td>0.001684</td>\n      <td>0.000710</td>\n      <td>0.001929</td>\n      <td>0.000775</td>\n      <td>0.001174</td>\n      <td>0.000757</td>\n      <td>0.004973</td>\n      <td>0.001106</td>\n      <td>0.001103</td>\n    </tr>\n    <tr>\n      <th>13196</th>\n      <td>0.003366</td>\n      <td>0.050964</td>\n      <td>0.005073</td>\n      <td>0.002017</td>\n      <td>0.001711</td>\n      <td>0.002411</td>\n      <td>0.002597</td>\n      <td>0.002938</td>\n      <td>0.001728</td>\n      <td>0.003586</td>\n      <td>...</td>\n      <td>0.002848</td>\n      <td>0.001304</td>\n      <td>0.002608</td>\n      <td>0.001346</td>\n      <td>0.003839</td>\n      <td>0.003638</td>\n      <td>0.002926</td>\n      <td>0.002350</td>\n      <td>0.004168</td>\n      <td>0.005286</td>\n    </tr>\n    <tr>\n      <th>44691</th>\n      <td>0.000008</td>\n      <td>0.000007</td>\n      <td>0.000009</td>\n      <td>0.000010</td>\n      <td>0.000006</td>\n      <td>0.000011</td>\n      <td>0.000008</td>\n      <td>0.000014</td>\n      <td>0.000008</td>\n      <td>0.000010</td>\n      <td>...</td>\n      <td>0.000013</td>\n      <td>0.000004</td>\n      <td>0.000009</td>\n      <td>0.000004</td>\n      <td>0.000007</td>\n      <td>0.000008</td>\n      <td>0.000013</td>\n      <td>0.000006</td>\n      <td>0.000013</td>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>27049</th>\n      <td>0.003204</td>\n      <td>0.002145</td>\n      <td>0.002397</td>\n      <td>0.001497</td>\n      <td>0.001864</td>\n      <td>0.001990</td>\n      <td>0.002514</td>\n      <td>0.002048</td>\n      <td>0.001896</td>\n      <td>0.001914</td>\n      <td>...</td>\n      <td>0.002614</td>\n      <td>0.001017</td>\n      <td>0.010982</td>\n      <td>0.001080</td>\n      <td>0.003761</td>\n      <td>0.002254</td>\n      <td>0.004858</td>\n      <td>0.001696</td>\n      <td>0.002612</td>\n      <td>0.003558</td>\n    </tr>\n    <tr>\n      <th>2054</th>\n      <td>0.002126</td>\n      <td>0.002760</td>\n      <td>0.003468</td>\n      <td>0.001363</td>\n      <td>0.001216</td>\n      <td>0.001532</td>\n      <td>0.001914</td>\n      <td>0.001806</td>\n      <td>0.001179</td>\n      <td>0.001723</td>\n      <td>...</td>\n      <td>0.001903</td>\n      <td>0.000860</td>\n      <td>0.002932</td>\n      <td>0.000906</td>\n      <td>0.004433</td>\n      <td>0.003405</td>\n      <td>0.002967</td>\n      <td>0.001461</td>\n      <td>0.002277</td>\n      <td>0.004366</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11284</th>\n      <td>0.000523</td>\n      <td>0.000643</td>\n      <td>0.000693</td>\n      <td>0.000893</td>\n      <td>0.000413</td>\n      <td>0.000555</td>\n      <td>0.000547</td>\n      <td>0.000603</td>\n      <td>0.000507</td>\n      <td>0.000724</td>\n      <td>...</td>\n      <td>0.000579</td>\n      <td>0.005467</td>\n      <td>0.000569</td>\n      <td>0.007300</td>\n      <td>0.000594</td>\n      <td>0.000900</td>\n      <td>0.000581</td>\n      <td>0.001389</td>\n      <td>0.000731</td>\n      <td>0.000729</td>\n    </tr>\n    <tr>\n      <th>44732</th>\n      <td>0.002772</td>\n      <td>0.002114</td>\n      <td>0.001996</td>\n      <td>0.002052</td>\n      <td>0.001288</td>\n      <td>0.001730</td>\n      <td>0.002448</td>\n      <td>0.001876</td>\n      <td>0.001525</td>\n      <td>0.002727</td>\n      <td>...</td>\n      <td>0.002229</td>\n      <td>0.001095</td>\n      <td>0.002113</td>\n      <td>0.001209</td>\n      <td>0.001957</td>\n      <td>0.002387</td>\n      <td>0.002200</td>\n      <td>0.002319</td>\n      <td>0.005422</td>\n      <td>0.003803</td>\n    </tr>\n    <tr>\n      <th>38158</th>\n      <td>0.001408</td>\n      <td>0.002021</td>\n      <td>0.002150</td>\n      <td>0.002780</td>\n      <td>0.000959</td>\n      <td>0.001524</td>\n      <td>0.001179</td>\n      <td>0.001777</td>\n      <td>0.001255</td>\n      <td>0.002955</td>\n      <td>...</td>\n      <td>0.001643</td>\n      <td>0.001993</td>\n      <td>0.001402</td>\n      <td>0.002226</td>\n      <td>0.001537</td>\n      <td>0.002533</td>\n      <td>0.001563</td>\n      <td>0.017039</td>\n      <td>0.002751</td>\n      <td>0.002489</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>0.002694</td>\n      <td>0.021154</td>\n      <td>0.003418</td>\n      <td>0.001392</td>\n      <td>0.001302</td>\n      <td>0.001732</td>\n      <td>0.001978</td>\n      <td>0.002040</td>\n      <td>0.001264</td>\n      <td>0.002375</td>\n      <td>...</td>\n      <td>0.002091</td>\n      <td>0.000933</td>\n      <td>0.001997</td>\n      <td>0.000961</td>\n      <td>0.003120</td>\n      <td>0.002509</td>\n      <td>0.002187</td>\n      <td>0.001629</td>\n      <td>0.002810</td>\n      <td>0.003636</td>\n    </tr>\n    <tr>\n      <th>15795</th>\n      <td>0.001341</td>\n      <td>0.001889</td>\n      <td>0.002124</td>\n      <td>0.001616</td>\n      <td>0.000764</td>\n      <td>0.001539</td>\n      <td>0.000964</td>\n      <td>0.001665</td>\n      <td>0.001018</td>\n      <td>0.004638</td>\n      <td>...</td>\n      <td>0.001959</td>\n      <td>0.000796</td>\n      <td>0.001161</td>\n      <td>0.000840</td>\n      <td>0.001407</td>\n      <td>0.001847</td>\n      <td>0.001452</td>\n      <td>0.001858</td>\n      <td>0.002538</td>\n      <td>0.003066</td>\n    </tr>\n  </tbody>\n</table>\n<p>35090 rows Ã— 370 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert X and y labels to numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "X_test = X_test.to_numpy()\n",
    "X_test = torch.from_numpy(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy()\n",
    "y_test = torch.from_numpy(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make X and y labels tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([35090, 370])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Tensor"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([35090])"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([35090, 370]), torch.Size([35090]))"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[6.8502e-04, 9.0484e-04, 9.7392e-04,  ..., 4.9735e-03, 1.1063e-03,\n          1.1026e-03],\n         [3.3660e-03, 5.0964e-02, 5.0731e-03,  ..., 2.3500e-03, 4.1677e-03,\n          5.2863e-03],\n         [7.5979e-06, 6.9994e-06, 8.8331e-06,  ..., 6.2486e-06, 1.2548e-05,\n          1.1754e-05],\n         [3.2042e-03, 2.1448e-03, 2.3967e-03,  ..., 1.6959e-03, 2.6117e-03,\n          3.5583e-03],\n         [2.1257e-03, 2.7597e-03, 3.4677e-03,  ..., 1.4607e-03, 2.2770e-03,\n          4.3658e-03]], dtype=torch.float64),\n tensor([0, 0, 1, 0, 0]))"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5], y_train[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch Workflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Create a model (input, output size, forward pass)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# 1. Construct a model class that subclasses nn.Module\n",
    "class NeuralNetwork_binary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
    "        self.layer_1 = nn.Linear(in_features=370, out_features=500) # takes in 370 features (X), produces 500 features TODO: How many output features here (meaning how many hidden layers?)\n",
    "        self.layer_2 = nn.Linear(in_features=500, out_features=500)\n",
    "        self.layer_3 = nn.Linear(in_features=500, out_features=1) # takes in 500 features, produces 1 feature (y)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "\n",
    "    # 3. Define a forward method containing the forward pass computation\n",
    "    def forward(self, x):\n",
    "        # Return the output of layer_2, a single feature, the same shape as y\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x))))) # computation goes through layer_1 first then the output of layer_1 goes through layer_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "NeuralNetwork_binary(\n  (layer_1): Linear(in_features=370, out_features=500, bias=True)\n  (layer_2): Linear(in_features=500, out_features=500, bias=True)\n  (layer_3): Linear(in_features=500, out_features=1, bias=True)\n  (relu): ReLU()\n)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Create an instance of the model and send it to target device\n",
    "model_0 = NeuralNetwork_binary().to(device)\n",
    "model_0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.) Construct loss and optimizer\n",
    "Iterate this:\n",
    "3.) Training Loop:\n",
    "    - forward pass: compute prediction\n",
    "    - backward pass: gradients\n",
    "    - Update weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define a Loss Function and Optimizer\n",
    "Because we have a binary classification problem: Use binary cross entropy as loss function\n",
    "We use Stochastic Gradient Descent as optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# Create a loss function\n",
    "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define a function for calculating accuracy as evaluation metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model\n",
    "1. Forward Pass: Model goes through all of the training data once\n",
    "2. Calculate the Loss\n",
    "3. Set optimizer gradients to zero\n",
    "4. Perform backpropagation on the Loss\n",
    "5. Update the parameters with gradient descent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Put data to target device TODO: What does that mean?\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.68989, Accuracy: 60.21% | Test loss: 0.68896, Test acc: 59.63%\n",
      "Epoch: 10 | Loss: 0.68093, Accuracy: 60.21% | Test loss: 0.68125, Test acc: 59.63%\n",
      "Epoch: 20 | Loss: 0.67651, Accuracy: 60.21% | Test loss: 0.67758, Test acc: 59.63%\n",
      "Epoch: 30 | Loss: 0.67432, Accuracy: 60.21% | Test loss: 0.67585, Test acc: 59.63%\n",
      "Epoch: 40 | Loss: 0.67323, Accuracy: 60.21% | Test loss: 0.67505, Test acc: 59.63%\n",
      "Epoch: 50 | Loss: 0.67269, Accuracy: 60.21% | Test loss: 0.67470, Test acc: 59.63%\n",
      "Epoch: 60 | Loss: 0.67242, Accuracy: 60.21% | Test loss: 0.67456, Test acc: 59.63%\n",
      "Epoch: 70 | Loss: 0.67228, Accuracy: 60.21% | Test loss: 0.67451, Test acc: 59.63%\n",
      "Epoch: 80 | Loss: 0.67221, Accuracy: 60.21% | Test loss: 0.67450, Test acc: 59.63%\n",
      "Epoch: 90 | Loss: 0.67218, Accuracy: 60.21% | Test loss: 0.67451, Test acc: 59.63%\n"
     ]
    }
   ],
   "source": [
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass (model outputs raw logits)\n",
    "    y_logits = model_0(X_train.float()).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
    "\n",
    "    # 2. Calculate loss/accuracy\n",
    "    loss = loss_fn(y_logits,\n",
    "                   y_train.float())\n",
    "    acc = accuracy_fn(y_true=y_train.float(),\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model_0(X_test.float()).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test.float())\n",
    "        test_acc = accuracy_fn(y_true=y_test.float(),\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}